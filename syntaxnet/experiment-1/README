This directory contains CONLL files generated by SyntaxNet default
parser for Portuguese.  To reproduce, clone the SyntaxNet repository
from:

https://github.com/tensorflow/models

Next, download the Portuguese trained model, available from:

https://github.com/tensorflow/models/blob/master/syntaxnet/universal.md

Next, you need to extract the sentences from the DHBB files, since the
SyntaxNet default parser only deals with sentences, one per line.

In this experiment we will use WKS for the sentences and tokenization,
so we can properly align the SyntaxNet output to WKS output.

Use the extract-sentences.py to extract the sentences from each ground
truth file in the WKS directory.

Next, just run syntaxnet over each sentence file as follows:

cat <file> | <repo>/syntaxnet/models/syntaxnet/syntaxnet/models/parsey_universal/parse.sh <lang-repo>/Portuguese
